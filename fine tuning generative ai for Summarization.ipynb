{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyP0pXeupsnIkqZ7S+MraErj"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"f449d9b7575e40b7b2690df235e767b8":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_574aaa84022e488e870ecfc1b9c0ba10","IPY_MODEL_732ce4ba1c044930999aef99bff9593e","IPY_MODEL_3c048e9569ac4b939a2957086109376b"],"layout":"IPY_MODEL_47b4eda4ba1d46319bfafee0c21e658d"}},"574aaa84022e488e870ecfc1b9c0ba10":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_dd422b5a26b2401aa72d628c1576aabe","placeholder":"​","style":"IPY_MODEL_40e9e2c8a3114ca5bf96fe5fc3d53c15","value":"100%"}},"732ce4ba1c044930999aef99bff9593e":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_a56ee70ea9bd41e58c884274f4c11517","max":3,"min":0,"orientation":"horizontal","style":"IPY_MODEL_3538aa57184448e2abd3adf24475f28f","value":3}},"3c048e9569ac4b939a2957086109376b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b1fda788c8be4a15a239125e5cd07135","placeholder":"​","style":"IPY_MODEL_9beaa08d95694486ba41b1d8f23dde2f","value":" 3/3 [00:00&lt;00:00,  6.66it/s]"}},"47b4eda4ba1d46319bfafee0c21e658d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"dd422b5a26b2401aa72d628c1576aabe":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"40e9e2c8a3114ca5bf96fe5fc3d53c15":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a56ee70ea9bd41e58c884274f4c11517":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3538aa57184448e2abd3adf24475f28f":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"b1fda788c8be4a15a239125e5cd07135":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9beaa08d95694486ba41b1d8f23dde2f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"960536878c174854bb7a2f5f07451c79":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_69cf0fb42252460ca86b2ee8d1812e48","IPY_MODEL_5298e29692e343e0ac2bd2b79e0310d2","IPY_MODEL_1002925cf9744a06b3ca29373a5ed313"],"layout":"IPY_MODEL_c2e9a1ccd9954b25bff54adf4c2028a1"}},"69cf0fb42252460ca86b2ee8d1812e48":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_12b54d6174d9478b892b7d6ff963cdbf","placeholder":"​","style":"IPY_MODEL_def4ffc1d60746838241d79a84a67e21","value":"Map: 100%"}},"5298e29692e343e0ac2bd2b79e0310d2":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_a43ce9c72e6e4a7c91033ddba64f82b2","max":1500,"min":0,"orientation":"horizontal","style":"IPY_MODEL_754b86ac78f149a7858a5948b685347a","value":1500}},"1002925cf9744a06b3ca29373a5ed313":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_cd34532401c548e9b5d0085d5d17962d","placeholder":"​","style":"IPY_MODEL_174fc4e566c84850a741ce6cf75cda43","value":" 1500/1500 [00:02&lt;00:00, 546.18 examples/s]"}},"c2e9a1ccd9954b25bff54adf4c2028a1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":"hidden","width":null}},"12b54d6174d9478b892b7d6ff963cdbf":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"def4ffc1d60746838241d79a84a67e21":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a43ce9c72e6e4a7c91033ddba64f82b2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"754b86ac78f149a7858a5948b685347a":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"cd34532401c548e9b5d0085d5d17962d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"174fc4e566c84850a741ce6cf75cda43":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4dfb81b9358e4002ac8fb853798e0d26":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_6c3b71bc561942fe9d0aacb3ad8a267d","IPY_MODEL_4285daf7b9a245cfad851036a4fbddea","IPY_MODEL_83b3d7c5fa6e46b290b54319ee11329d"],"layout":"IPY_MODEL_4351f603d15f44a78a6d5ab2956197c8"}},"6c3b71bc561942fe9d0aacb3ad8a267d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_241eece99c5e493ba483eb75cb101421","placeholder":"​","style":"IPY_MODEL_a045145bacdf49ad9ee2d5598f83fc37","value":"Filter: 100%"}},"4285daf7b9a245cfad851036a4fbddea":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_303aa6c6a7e448139357dfbe789414b1","max":1500,"min":0,"orientation":"horizontal","style":"IPY_MODEL_f52b89397a6b489395a9daff2507d010","value":1500}},"83b3d7c5fa6e46b290b54319ee11329d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8c33cccef0b74a5f859a5dd661949ac2","placeholder":"​","style":"IPY_MODEL_18b66add57a647c5bf70856746707d04","value":" 1500/1500 [00:01&lt;00:00, 1254.65 examples/s]"}},"4351f603d15f44a78a6d5ab2956197c8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":"hidden","width":null}},"241eece99c5e493ba483eb75cb101421":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a045145bacdf49ad9ee2d5598f83fc37":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"303aa6c6a7e448139357dfbe789414b1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f52b89397a6b489395a9daff2507d010":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"8c33cccef0b74a5f859a5dd661949ac2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"18b66add57a647c5bf70856746707d04":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"markdown","source":["# Fine-Tuning a Generative AI model for dialogue summarization\n","\n","use FLAN-T5 model, which provides high quality instruction tuned model and can summarize text out of the box, I will explore the full fine tuning approach and evaluate the result using Rouge metrics, then perform Parameter efficient Fine Tuning (PEFT), evaluate the result model and see the benefits of PEFT."],"metadata":{"id":"hHHU2b4ucsiU"}},{"cell_type":"markdown","source":["# Content\n","- 1.Load require dependencies,Dataset and LLM\n","  - 1.1-load the dataset and LLM\n","  - 1.2-test the model with zero shot inference\n","\n","\n","- 2.Perform Full Fine Tuning\n","  - 2.1-process the Dialogue summary dataset\n","  - 2.2-Fine-tune the model with perprocessed dataset\n","  - 2.3-Evaluate the model quality with Human Evaluate\n","  - 2.4-Evaluate the model quality with Rouge metrics.\n","- 3.Perform Parameter Efficient Fine Tuning\n","  - 3.1-Setup the PEFt/LoRa model for fine-tuning\n","  - 3.2-Train PEFT adapter\n","  - 3.3-Evaluate model quality with Human Evaluate\n","  - 3.4-Evaluate model quality with Rouge Metrics\n"],"metadata":{"id":"_tQ2o000fJUm"}},{"cell_type":"code","execution_count":1,"metadata":{"id":"9_TdvQgkaFEx","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1694083681717,"user_tz":-180,"elapsed":264805,"user":{"displayName":"Ahmed Toba","userId":"06597376039079993537"}},"outputId":"64f7bb90-08ac-422a-be03-78fabb0dacbf"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: pip in /usr/local/lib/python3.10/dist-packages (23.1.2)\n","Collecting pip\n","  Downloading pip-23.2.1-py3-none-any.whl (2.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: pip\n","  Attempting uninstall: pip\n","    Found existing installation: pip 23.1.2\n","    Uninstalling pip-23.1.2:\n","      Successfully uninstalled pip-23.1.2\n","Successfully installed pip-23.2.1\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m887.5/887.5 MB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.6/4.6 MB\u001b[0m \u001b[31m97.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m849.3/849.3 kB\u001b[0m \u001b[31m54.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m557.1/557.1 MB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.1/317.1 MB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.0/21.0 MB\u001b[0m \u001b[31m74.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","torchaudio 2.0.2+cu118 requires torch==2.0.1, but you have torch 1.13.1 which is incompatible.\n","torchtext 0.15.2 requires torch==2.0.1, but you have torch 1.13.1 which is incompatible.\n","torchtext 0.15.2 requires torchdata==0.6.1, but you have torchdata 0.5.1 which is incompatible.\n","torchvision 0.15.2+cu118 requires torch==2.0.1, but you have torch 1.13.1 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.8/6.8 MB\u001b[0m \u001b[31m17.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m468.7/468.7 kB\u001b[0m \u001b[31m34.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m81.4/81.4 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.8/56.8 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m29.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m110.5/110.5 kB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.3/134.3 kB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m21.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m251.2/251.2 kB\u001b[0m \u001b[31m21.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m17.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Building wheel for rouge_score (setup.py) ... \u001b[?25l\u001b[?25hdone\n","\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n","\u001b[0m"]}],"source":["%pip install --upgrade pip\n","%pip install --disable-pip-version-check \\\n","  torch==1.13.1 \\\n","  torchdata==0.5.1 --quiet\n","%pip install \\\n","  transformers==4.27.2 \\\n","  datasets==2.11.0 \\\n","  evaluate==0.4.0 \\\n","  rouge_score==0.1.2 \\\n","  loralib==0.1.0 \\\n","  peft==0.3.0 --quiet"]},{"cell_type":"markdown","source":["# Importing"],"metadata":{"id":"kbjRPCsKkkCw"}},{"cell_type":"code","source":["from datasets import load_dataset\n","from transformers import AutoModelForSeq2SeqLM , AutoTokenizer , GenerationConfig , TrainingArguments , Trainer\n","import torch\n","import numpy as np\n","import pandas as pd\n","import time\n","import evaluate"],"metadata":{"id":"w0g_Dt06i_1D","executionInfo":{"status":"ok","timestamp":1694093675320,"user_tz":-180,"elapsed":15197,"user":{"displayName":"Ahmed Toba","userId":"06597376039079993537"}}},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":["# 1.1 Load dataset and LLM\n","\n","[DialogSum](https://huggingface.co/datasets/knkarthick/dialogsum) Hugging Face dataset, it contains 10,000+ Dialogues with the corresponding manually labeled summarize and topics."],"metadata":{"id":"LnJ7RVCMkqM9"}},{"cell_type":"code","source":["hugging_face_model_name =  'google/flan-t5-base'\n","hugging_face_data_name  =  'knkarthick/dialogsum'\n","\n","\n","#loading data\n","data = load_dataset(hugging_face_data_name)\n","# load model and tokenizer\n","original_model =AutoModelForSeq2SeqLM.from_pretrained(hugging_face_model_name)\n","tokenizer      =AutoTokenizer.from_pretrained(hugging_face_model_name)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":86,"referenced_widgets":["f449d9b7575e40b7b2690df235e767b8","574aaa84022e488e870ecfc1b9c0ba10","732ce4ba1c044930999aef99bff9593e","3c048e9569ac4b939a2957086109376b","47b4eda4ba1d46319bfafee0c21e658d","dd422b5a26b2401aa72d628c1576aabe","40e9e2c8a3114ca5bf96fe5fc3d53c15","a56ee70ea9bd41e58c884274f4c11517","3538aa57184448e2abd3adf24475f28f","b1fda788c8be4a15a239125e5cd07135","9beaa08d95694486ba41b1d8f23dde2f"]},"id":"KkZYuwJoke1m","executionInfo":{"status":"ok","timestamp":1694093694041,"user_tz":-180,"elapsed":18725,"user":{"displayName":"Ahmed Toba","userId":"06597376039079993537"}},"outputId":"664e5fe2-45c7-4c54-f1f4-0a4cb2a055ac"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stderr","text":["WARNING:datasets.builder:Found cached dataset csv (/root/.cache/huggingface/datasets/knkarthick___csv/knkarthick--dialogsum-c8fac5d84cd35861/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1)\n"]},{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/3 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f449d9b7575e40b7b2690df235e767b8"}},"metadata":{}}]},{"cell_type":"code","source":["# showing data\n","data"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4fUWV_XCmSI-","executionInfo":{"status":"ok","timestamp":1694093694042,"user_tz":-180,"elapsed":8,"user":{"displayName":"Ahmed Toba","userId":"06597376039079993537"}},"outputId":"310918dc-d50d-4eac-c45a-3730c418710a"},"execution_count":3,"outputs":[{"output_type":"execute_result","data":{"text/plain":["DatasetDict({\n","    train: Dataset({\n","        features: ['id', 'dialogue', 'summary', 'topic'],\n","        num_rows: 12460\n","    })\n","    test: Dataset({\n","        features: ['id', 'dialogue', 'summary', 'topic'],\n","        num_rows: 1500\n","    })\n","    validation: Dataset({\n","        features: ['id', 'dialogue', 'summary', 'topic'],\n","        num_rows: 500\n","    })\n","})"]},"metadata":{},"execution_count":3}]},{"cell_type":"markdown","source":["pull out the number of parameters and find out, how many of them are trainable"],"metadata":{"id":"pGGU0lsonapU"}},{"cell_type":"code","source":["def print_the_number_of_trainable_parameters(model):\n","  trainable = 0\n","  all_params= 0\n","\n","  for _, params in model.named_parameters():\n","    all_params+= params.numel()\n","    if params.requires_grad:\n","      trainable +=params.numel()\n","  return f'Trainable model parameters :{trainable}\\nAll parameters :{all_params}\\npercentage of trainable parameters :{100* trainable/all_params:.2f}%'\n","\n","\n","\n","\n","print(print_the_number_of_trainable_parameters(original_model))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eIC7FtlQmjgb","executionInfo":{"status":"ok","timestamp":1694093694636,"user_tz":-180,"elapsed":7,"user":{"displayName":"Ahmed Toba","userId":"06597376039079993537"}},"outputId":"e8ddfc10-27dd-40ec-aeb5-9e6a002cb0ec"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Trainable model parameters :247577856\n","All parameters :247577856\n","percentage of trainable parameters :100.00%\n"]}]},{"cell_type":"markdown","source":["# 1.2 test the model with zero shot inference\n","\n","you can say that the model struggles to summarize the dialogue compared to the base line summary, but it does pull out important information from the text, which indicate that the model can be fine-tuned to the task at hand."],"metadata":{"id":"SqcLgCekQJxe"}},{"cell_type":"code","source":["index = 200\n","\n","zero_dialogue = data['test'][index]['dialogue']\n","zero_summary  = data['test'][index]['summary']\n","\n","zero_prompt = f'''\n","summarize the following conversation.\n","\n","{zero_dialogue}\n","\n","summary:\n"," '''\n","\n","\n","\n","input   = tokenizer(zero_prompt , return_tensors='pt')\n","generate= original_model.generate(input['input_ids'] , max_new_tokens=200)[0]\n","output  = tokenizer.decode(generate , skip_special_tokens=True)\n","\n","\n","dash_line = '-'.join('' for i in range(100))\n","\n","# show results\n","print(dash_line)\n","print(f'Prompt:\\n{zero_prompt}')\n","print(dash_line)\n","print(f'Human summary:\\n{zero_summary}')\n","print(dash_line)\n","print(f'Model generate:\\n{output}')\n","\n"],"metadata":{"id":"Yub18h3BpRHY","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1694093700373,"user_tz":-180,"elapsed":5741,"user":{"displayName":"Ahmed Toba","userId":"06597376039079993537"}},"outputId":"add17983-7110-493a-f9bf-e20c07227b0b"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["---------------------------------------------------------------------------------------------------\n","Prompt:\n","\n","summarize the following conversation.\n","\n","#Person1#: Have you considered upgrading your system?\n","#Person2#: Yes, but I'm not sure what exactly I would need.\n","#Person1#: You could consider adding a painting program to your software. It would allow you to make up your own flyers and banners for advertising.\n","#Person2#: That would be a definite bonus.\n","#Person1#: You might also want to upgrade your hardware because it is pretty outdated now.\n","#Person2#: How can we do that?\n","#Person1#: You'd probably need a faster processor, to begin with. And you also need a more powerful hard disc, more memory and a faster modem. Do you have a CD-ROM drive?\n","#Person2#: No.\n","#Person1#: Then you might want to add a CD-ROM drive too, because most new software programs are coming out on Cds.\n","#Person2#: That sounds great. Thanks.\n","\n","summary:\n"," \n","---------------------------------------------------------------------------------------------------\n","Human summary:\n","#Person1# teaches #Person2# how to upgrade software and hardware in #Person2#'s system.\n","---------------------------------------------------------------------------------------------------\n","Model generate:\n","#Person1#: Have you considered upgrading your system?\n"]}]},{"cell_type":"markdown","source":["# 2.Perform Full Fine Tuning"],"metadata":{"id":"Ha_lEC9MUDZy"}},{"cell_type":"markdown","source":["# 2.1-process the dialogue summaray dataset\n","\n","we need convert the data dialogue-summart(prompt-respons) pairs into explici instructions for the LLM.prepend an instruction to the start of the Dialogue with ` Summarize the following conversation ` and to the start of the summary with ` Summary ` as the following\n","\n","\n","Training Prompt(dialogue):\n","```\n","Summarize the following conversation.\n","\n","    Chris: This is his part of the conversation.\n","    Antje: This is her part of the conversation.\n","    \n","Summary:\n","```\n","\n","\n","Training Response(summary):\n","\n","`Both Chris and Antje participated in the conversation.`\n","\n","the preprocess prompt and response data into tokens and pull up inputs_ids\n"],"metadata":{"id":"JZLe8FEAUXOV"}},{"cell_type":"code","source":["def tokenize_function(example):\n","\n","\n","  start_prompt = 'Summarize the following conversation.\\n\\n'\n","  start_summary= '\\n\\nSummary: '\n","  prompt =  [start_prompt + dialogue + start_summary for dialogue in example['dialogue']]\n","\n","  example['input_ids'] = tokenizer(prompt , return_tensors='pt' , padding ='max_length' , truncation=True).input_ids\n","  example['labels']    = tokenizer(example['summary'] , return_tensors='pt' , padding ='max_length' , truncation=True).input_ids\n","\n","  return example\n","\n","\n","\n","tokenized_data = data.map(tokenize_function , batched=True)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":72,"referenced_widgets":["960536878c174854bb7a2f5f07451c79","69cf0fb42252460ca86b2ee8d1812e48","5298e29692e343e0ac2bd2b79e0310d2","1002925cf9744a06b3ca29373a5ed313","c2e9a1ccd9954b25bff54adf4c2028a1","12b54d6174d9478b892b7d6ff963cdbf","def4ffc1d60746838241d79a84a67e21","a43ce9c72e6e4a7c91033ddba64f82b2","754b86ac78f149a7858a5948b685347a","cd34532401c548e9b5d0085d5d17962d","174fc4e566c84850a741ce6cf75cda43"]},"id":"-PMcvpevS7JX","executionInfo":{"status":"ok","timestamp":1694093703453,"user_tz":-180,"elapsed":3088,"user":{"displayName":"Ahmed Toba","userId":"06597376039079993537"}},"outputId":"2629526a-2914-40dd-c9ae-6b73e671c940"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stderr","text":["WARNING:datasets.arrow_dataset:Loading cached processed dataset at /root/.cache/huggingface/datasets/knkarthick___csv/knkarthick--dialogsum-c8fac5d84cd35861/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1/cache-54ed01095400c6c8.arrow\n"]},{"output_type":"display_data","data":{"text/plain":["Map:   0%|          | 0/1500 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"960536878c174854bb7a2f5f07451c79"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["WARNING:datasets.arrow_dataset:Loading cached processed dataset at /root/.cache/huggingface/datasets/knkarthick___csv/knkarthick--dialogsum-c8fac5d84cd35861/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1/cache-2543823bde4eb167.arrow\n"]}]},{"cell_type":"code","source":["tokenized_data=tokenized_data.remove_columns(['id', 'topic', 'dialogue', 'summary',])\n","tokenized_data"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"omGmrPwneGuZ","executionInfo":{"status":"ok","timestamp":1694093703454,"user_tz":-180,"elapsed":13,"user":{"displayName":"Ahmed Toba","userId":"06597376039079993537"}},"outputId":"c8158e67-a063-4d2c-a86e-5c4e7beff6ca"},"execution_count":7,"outputs":[{"output_type":"execute_result","data":{"text/plain":["DatasetDict({\n","    train: Dataset({\n","        features: ['input_ids', 'labels'],\n","        num_rows: 12460\n","    })\n","    test: Dataset({\n","        features: ['input_ids', 'labels'],\n","        num_rows: 1500\n","    })\n","    validation: Dataset({\n","        features: ['input_ids', 'labels'],\n","        num_rows: 500\n","    })\n","})"]},"metadata":{},"execution_count":7}]},{"cell_type":"markdown","source":["we will subsample the dataset to save some time\n","\n","---\n","\n"],"metadata":{"id":"pICyLwI6e-nv"}},{"cell_type":"code","source":["tokenized_data = tokenized_data.filter(lambda example , index : index % 100==0 , with_indices=True)\n","tokenized_data"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":315,"referenced_widgets":["4dfb81b9358e4002ac8fb853798e0d26","6c3b71bc561942fe9d0aacb3ad8a267d","4285daf7b9a245cfad851036a4fbddea","83b3d7c5fa6e46b290b54319ee11329d","4351f603d15f44a78a6d5ab2956197c8","241eece99c5e493ba483eb75cb101421","a045145bacdf49ad9ee2d5598f83fc37","303aa6c6a7e448139357dfbe789414b1","f52b89397a6b489395a9daff2507d010","8c33cccef0b74a5f859a5dd661949ac2","18b66add57a647c5bf70856746707d04"]},"id":"PKRhjBnke41Z","executionInfo":{"status":"ok","timestamp":1694093704547,"user_tz":-180,"elapsed":1103,"user":{"displayName":"Ahmed Toba","userId":"06597376039079993537"}},"outputId":"f967682b-abc9-4c7f-c31b-312d35022a9c"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stderr","text":["WARNING:datasets.arrow_dataset:Loading cached processed dataset at /root/.cache/huggingface/datasets/knkarthick___csv/knkarthick--dialogsum-c8fac5d84cd35861/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1/cache-aade38093df9ebda.arrow\n"]},{"output_type":"display_data","data":{"text/plain":["Filter:   0%|          | 0/1500 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4dfb81b9358e4002ac8fb853798e0d26"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["WARNING:datasets.arrow_dataset:Loading cached processed dataset at /root/.cache/huggingface/datasets/knkarthick___csv/knkarthick--dialogsum-c8fac5d84cd35861/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1/cache-e13d05c7bd54c045.arrow\n"]},{"output_type":"execute_result","data":{"text/plain":["DatasetDict({\n","    train: Dataset({\n","        features: ['input_ids', 'labels'],\n","        num_rows: 125\n","    })\n","    test: Dataset({\n","        features: ['input_ids', 'labels'],\n","        num_rows: 15\n","    })\n","    validation: Dataset({\n","        features: ['input_ids', 'labels'],\n","        num_rows: 5\n","    })\n","})"]},"metadata":{},"execution_count":8}]},{"cell_type":"markdown","source":["# 2.2-Fine tune the model with preprocessed data\n","\n","\n","Now utilize the built-in Hugging Face `Trainer` class (see the documentation [here](https://huggingface.co/docs/transformers/main_classes/trainer)). Pass the preprocessed dataset with reference to the original model"],"metadata":{"id":"gE2cAIegf33z"}},{"cell_type":"code","source":["output_dir = f'/content/sample_data/dialogue-summary-training-{str(int(time.time()))}'\n","\n","training_args = TrainingArguments(\n","    output_dir       = output_dir ,\n","    learning_rate    = 1e-5 ,\n","    num_train_epochs = 1 ,\n","    weight_decay     = 0.01 ,\n","    logging_steps    = 1,\n","    max_steps        = 1\n",")\n","\n","\n","trainer = Trainer(\n","    model         = original_model ,\n","    args          = training_args ,\n","    train_dataset = tokenized_data['train'],\n","    eval_dataset  = tokenized_data['validation']\n",")\n","\n"],"metadata":{"id":"Bw7F7jPkffbg","executionInfo":{"status":"ok","timestamp":1694093729986,"user_tz":-180,"elapsed":352,"user":{"displayName":"Ahmed Toba","userId":"06597376039079993537"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":["# trainer.train()"],"metadata":{"id":"PHjTAo3Yrki9","executionInfo":{"status":"ok","timestamp":1694093740150,"user_tz":-180,"elapsed":436,"user":{"displayName":"Ahmed Toba","userId":"06597376039079993537"}}},"execution_count":14,"outputs":[]},{"cell_type":"markdown","source":["Training a fully fine-tuned version of the model would take a few hours on a GPU. To save time, download a checkpoint of the fully fine-tuned model to use in the rest of this notebook. This fully fine-tuned model will also be referred to as the **instruct model**"],"metadata":{"id":"YTHb9WWw2EJP"}},{"cell_type":"markdown","source":["<a name='2.3'></a>\n","### 2.3 - Evaluate the Model Qualitatively (Human Evaluation)\n","\n","As with many GenAI applications, a qualitative approach where you ask yourself the question \"Is my model behaving the way it is supposed to?\" is usually a good starting point. In the example below (the same one we started this notebook with), you can see how the fine-tuned model is able to create a reasonable summary of the dialogue compared to the original inability to understand what is being asked of the model."],"metadata":{"id":"Hxvp5NWE76jy"}},{"cell_type":"markdown","source":["<a name='3'></a>\n","## 3 - Perform Parameter Efficient Fine-Tuning (PEFT)\n","\n","Now, let's perform **Parameter Efficient Fine-Tuning (PEFT)** fine-tuning as opposed to \"full fine-tuning\" as you did above. PEFT is a form of instruction fine-tuning that is much more efficient than full fine-tuning - with comparable evaluation results as you will see soon.\n","\n","PEFT is a generic term that includes **Low-Rank Adaptation (LoRA)** and prompt tuning (which is NOT THE SAME as prompt engineering!). In most cases, when someone says PEFT, they typically mean LoRA. LoRA, at a very high level, allows the user to fine-tune their model using fewer compute resources (in some cases, a single GPU). After fine-tuning for a specific task, use case, or tenant with LoRA, the result is that the original LLM remains unchanged and a newly-trained “LoRA adapter” emerges. This LoRA adapter is much, much smaller than the original LLM - on the order of a single-digit % of the original LLM size (MBs vs GBs).  \n","\n","That said, at inference time, the LoRA adapter needs to be reunited and combined with its original LLM to serve the inference request.  The benefit, however, is that many LoRA adapters can re-use the original LLM which reduces overall memory requirements when serving multiple tasks and use cases."],"metadata":{"id":"uHXKd9o78-j4"}},{"cell_type":"markdown","source":["<a name='3.1'></a>\n","### 3.1 - Setup the PEFT/LoRA model for Fine-Tuning\n","\n","You need to set up the PEFT/LoRA model for fine-tuning with a new layer/parameter adapter. Using PEFT/LoRA, you are freezing the underlying LLM and only training the adapter. Have a look at the LoRA configuration below. Note the rank (`r`) hyper-parameter, which defines the rank/dimension of the adapter to be trained."],"metadata":{"id":"WwgrF4YK9CKq"}},{"cell_type":"code","source":["from peft import LoraConfig, get_peft_model, TaskType\n","\n","lora_config = LoraConfig(\n","    r=32, # Rank\n","    lora_alpha=32,\n","    target_modules=[\"q\", \"v\"],\n","    lora_dropout=0.05,\n","    bias=\"none\",\n","    task_type=TaskType.SEQ_2_SEQ_LM # FLAN-T5\n",")"],"metadata":{"id":"BBZ65gTj2M3v","executionInfo":{"status":"ok","timestamp":1694095398075,"user_tz":-180,"elapsed":336,"user":{"displayName":"Ahmed Toba","userId":"06597376039079993537"}}},"execution_count":18,"outputs":[]},{"cell_type":"code","source":["peft_model = get_peft_model(original_model,\n","                            lora_config)\n","print(print_the_number_of_trainable_parameters(peft_model))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ImYvVA2v2M0_","executionInfo":{"status":"ok","timestamp":1694095441285,"user_tz":-180,"elapsed":2452,"user":{"displayName":"Ahmed Toba","userId":"06597376039079993537"}},"outputId":"71e199e9-b8ad-4b0e-dec3-b8e6f51d80f0"},"execution_count":19,"outputs":[{"output_type":"stream","name":"stdout","text":["Trainable model parameters :3538944\n","All parameters :251116800\n","percentage of trainable parameters :1.41%\n"]}]},{"cell_type":"code","source":["output_dir = f'./peft-dialogue-summary-training-{str(int(time.time()))}'\n","\n","peft_training_args = TrainingArguments(\n","    output_dir=output_dir,\n","    auto_find_batch_size=True,\n","    learning_rate=1e-3, # Higher learning rate than full fine-tuning.\n","    num_train_epochs=1,\n","    logging_steps=1,\n","    max_steps=1\n",")\n","\n","peft_trainer = Trainer(\n","    model=peft_model,\n","    args=peft_training_args,\n","    train_dataset=tokenized_data[\"train\"],\n",")"],"metadata":{"id":"C1utPJ7s2Mym","executionInfo":{"status":"ok","timestamp":1694095468729,"user_tz":-180,"elapsed":286,"user":{"displayName":"Ahmed Toba","userId":"06597376039079993537"}}},"execution_count":21,"outputs":[]},{"cell_type":"code","source":["peft_trainer.train()\n","\n","# peft_model_path=\"./peft-dialogue-summary-checkpoint-local\"\n","\n","# peft_trainer.model.save_pretrained(peft_model_path)\n","# tokenizer.save_pretrained(peft_model_path)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5Tz4PO_u2Mwo","outputId":"3b90081d-9ed0-4106-ea1c-a46d0e70fb12"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n"]}]},{"cell_type":"code","source":["peft_trainer.evaluate()"],"metadata":{"id":"eILuqZkL2Mns"},"execution_count":null,"outputs":[]}]}